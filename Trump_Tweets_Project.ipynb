{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trump Tweets - Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiosas/Trump_Tweets/blob/master/Trump_Tweets_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBZ5O1Rt7k6U",
        "colab_type": "text"
      },
      "source": [
        "## ***Initial Setup***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70QsN6iA7mcj",
        "colab_type": "text"
      },
      "source": [
        "### ***Environment Setup***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8pw5PhZ7IAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHkoT1M7vou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_name = 'Trump_Tweets'\n",
        "DATA_DIR = Path(f'data/{dir_name}')\n",
        "MODEL_DIR = Path(f'model/{dir_name}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiqtZbSh74fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "FIRST_RUN = not os.path.exists(str(MODEL_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ2vw6oq7-xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not IN_COLAB:\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jopveXb8Dz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FIRST_RUN:\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "if IN_COLAB and FIRST_RUN:\n",
        "    !pip install -q --upgrade scikit-optimize\n",
        "    !pip install -q -U --pre efficientnet\n",
        "    # !pip install -q -U tensorflow-datasets\n",
        "    !pip install -q -U --no-deps tensorflow-addons~=0.6\n",
        "    !pip install -q -U tensorflow_hub\n",
        "    !pip install -q -U git+https://github.com/huggingface/transformers    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W7gJzhy8tPs",
        "colab_type": "text"
      },
      "source": [
        "### ***Kaggle Setup***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpKDbei-8laR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_kaggle():\n",
        "    x = !ls kaggle.json\n",
        "    assert x == ['kaggle.json'], 'Upload kaggle.json'\n",
        "    !mkdir /root/.kaggle\n",
        "    !mv kaggle.json /root/.kaggle\n",
        "    !chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO_OW_I485LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure you've uploaded 'kaggle.json' file into Colab\n",
        "if IN_COLAB and FIRST_RUN:\n",
        "    setup_kaggle()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itkj3QMy9Bh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1qsCvUI9HTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IN_COLAB and FIRST_RUN:\n",
        "    kaggle.api.authenticate()\n",
        "    kaggle.api.dataset_download_files(\n",
        "        dataset='austinvernsonger/donaldtrumptweets',\n",
        "        path=DATA_DIR,\n",
        "        unzip=True,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3jTal2B-H8D",
        "colab_type": "text"
      },
      "source": [
        "### ***Importing Dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k08UgIL9gbL",
        "colab_type": "code",
        "outputId": "bd4068b9-5e85-4a10-b047-eab6c4154dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ett300eZ-SwC",
        "colab_type": "code",
        "outputId": "3ec5f50c-e864-47c6-cb3e-75a648553042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from imports import *\n",
        "\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAI_-l4-Xr-",
        "colab_type": "code",
        "outputId": "b80701b3-fde3-48d6-9e84-ff21e997aa37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr33nFIH-dEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FIRST_RUN:\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqr62av-h4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByFPgb7-o1B",
        "colab_type": "text"
      },
      "source": [
        "## ***Data Description***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3fAYoe-25U",
        "colab_type": "text"
      },
      "source": [
        "### **Content**\n",
        "\n",
        "![Trump](https://cdn.cnn.com/cnnnext/dam/assets/180925135532-gfx-twitter-donald-trump-tweet-exlarge-169.jpg)\n",
        "\n",
        "This dataset is a collection of more than 30,000 Donald Trump tweets, dating from 2009 to 2016.\n",
        "\n",
        "The columns of the data file are:\n",
        "\n",
        "* Text — full message posted on Twitter,\n",
        "* Date — date when Twitter message was posted,\n",
        "* Favorites — number of times Twitter message was marked as favorite by the other users,\n",
        "* Retweets — number of times Twitter message was re-posted or shared by the other users,\n",
        "* Tweet ID — ID of Twitter message.\n",
        "\n",
        "\n",
        "We will use this dataset to create a word-level text generator using a pretrained architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6P2k7ur_B1g",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Exploration***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY4PVmqjhGA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the data from the file\n",
        "raw_data = pd.read_csv(DATA_DIR/'data.csv', low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz3qy-yyhRac",
        "colab_type": "code",
        "outputId": "c6117b1c-8c08-40f7-e10a-1b64d031f2c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of rows in the dataset:', raw_data.shape[0])\n",
        "print('Number of columns in the dataset:', raw_data.shape[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 31175\n",
            "Number of columns in the dataset: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0iUS5nhZji",
        "colab_type": "code",
        "outputId": "ac3d688c-50fe-4d58-d5b2-aba9ea06f3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "raw_data.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31175 entries, 0 to 31174\n",
            "Data columns (total 5 columns):\n",
            "Text         31174 non-null object\n",
            "Date         31175 non-null object\n",
            "Favorites    31175 non-null int64\n",
            "Retweets     31175 non-null int64\n",
            "Tweet ID     31175 non-null int64\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFwlkllhhfDY",
        "colab_type": "code",
        "outputId": "628c022a-a053-4c32-8e53-92e89a86897f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "raw_data.describe(include='all')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31174</td>\n",
              "      <td>31175</td>\n",
              "      <td>31175.000000</td>\n",
              "      <td>31175.000000</td>\n",
              "      <td>3.117500e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>31057</td>\n",
              "      <td>31174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
              "      <td>2016-01-14 05:45:41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3167.715926</td>\n",
              "      <td>1255.764555</td>\n",
              "      <td>4.654273e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11655.175669</td>\n",
              "      <td>4638.563418</td>\n",
              "      <td>1.789587e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.698309e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.185713e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>4.738490e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>643.000000</td>\n",
              "      <td>613.000000</td>\n",
              "      <td>6.108192e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>639223.000000</td>\n",
              "      <td>349873.000000</td>\n",
              "      <td>8.115643e+17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Text  ...      Tweet ID\n",
              "count                       31174  ...  3.117500e+04\n",
              "unique                      31057  ...           NaN\n",
              "top     MAKE AMERICA GREAT AGAIN!  ...           NaN\n",
              "freq                           11  ...           NaN\n",
              "mean                          NaN  ...  4.654273e+17\n",
              "std                           NaN  ...  1.789587e+17\n",
              "min                           NaN  ...  1.698309e+09\n",
              "25%                           NaN  ...  3.185713e+17\n",
              "50%                           NaN  ...  4.738490e+17\n",
              "75%                           NaN  ...  6.108192e+17\n",
              "max                           NaN  ...  8.115643e+17\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXBDGNsXG5cV",
        "colab_type": "code",
        "outputId": "b396b645-5f8c-4474-d441-24d5236b75ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have not heard any of the pundits or comment...</td>\n",
              "      <td>2016-12-21 13:29:38</td>\n",
              "      <td>14755</td>\n",
              "      <td>4055</td>\n",
              "      <td>811564284706689024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I would have done even better in the election,...</td>\n",
              "      <td>2016-12-21 13:24:29</td>\n",
              "      <td>11129</td>\n",
              "      <td>2789</td>\n",
              "      <td>811562990285848576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Campaigning to win the Electoral College is mu...</td>\n",
              "      <td>2016-12-21 13:15:14</td>\n",
              "      <td>14906</td>\n",
              "      <td>3925</td>\n",
              "      <td>811560662853939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes, it is true - Carlos Slim, the great busin...</td>\n",
              "      <td>2016-12-20 20:27:57</td>\n",
              "      <td>51424</td>\n",
              "      <td>12578</td>\n",
              "      <td>811307169043849216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>especially how to get people, even with an unl...</td>\n",
              "      <td>2016-12-20 13:09:18</td>\n",
              "      <td>35699</td>\n",
              "      <td>8008</td>\n",
              "      <td>811196778779463684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...            Tweet ID\n",
              "0  I have not heard any of the pundits or comment...  ...  811564284706689024\n",
              "1  I would have done even better in the election,...  ...  811562990285848576\n",
              "2  Campaigning to win the Electoral College is mu...  ...  811560662853939200\n",
              "3  Yes, it is true - Carlos Slim, the great busin...  ...  811307169043849216\n",
              "4  especially how to get people, even with an unl...  ...  811196778779463684\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jxy9SFo0MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoyFeX4ppicZ",
        "colab_type": "code",
        "outputId": "aff359a8-e89f-49e4-a549-98242acb7205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "raw_data.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31174 entries, 0 to 31174\n",
            "Data columns (total 5 columns):\n",
            "Text         31174 non-null object\n",
            "Date         31174 non-null object\n",
            "Favorites    31174 non-null int64\n",
            "Retweets     31174 non-null int64\n",
            "Tweet ID     31174 non-null int64\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM89EsBumorJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_col = 'Text'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SosGMaOwtXFQ",
        "colab_type": "text"
      },
      "source": [
        "## ***Data Preparation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9cgd7nuO0C",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Preprocessing - Vocabulary***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0O-6SwWondv",
        "colab_type": "code",
        "outputId": "7468a9bd-1b73-41d3-ba32-6a8fb14fc900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "text_corpus = \" \\n<TWEETEND>\\n \".join(raw_data[text_col].values)\n",
        "print(text_corpus[:1000])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have not heard any of the pundits or commentators discussing the fact that I spent FAR LESS MONEY on the win than Hillary on the loss! \n",
            "<TWEETEND>\n",
            " I would have done even better in the election, if that is possible, if the winner was based on popular vote - but would campaign differently \n",
            "<TWEETEND>\n",
            " Campaigning to win the Electoral College is much more difficult & sophisticated than the popular vote. Hillary focused on the wrong states! \n",
            "<TWEETEND>\n",
            " Yes, it is true - Carlos Slim, the great businessman from Mexico, called me about getting together for a meeting. We met, HE IS A GREAT GUY! \n",
            "<TWEETEND>\n",
            " especially how to get people, even with an unlimited budget, out to vote in the vital swing states ( and more). They focused on wrong states \n",
            "<TWEETEND>\n",
            " Bill Clinton stated that I called him after the election. Wrong, he called me (with a very nice congratulations). He \"doesn't know much\" ... \n",
            "<TWEETEND>\n",
            " \"@mike_pence: Congratulations to @RealDonaldTrump; officially elected President o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUP0CavQs3ig",
        "colab_type": "code",
        "outputId": "4e560cf2-4091-446a-b4ba-d619efd17ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Length of all characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of all characters in text corpus - 137\n",
            "Characters: \n",
            "\r !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz{|}~ £«®´º»Éèéíïñıĺ​‎‏–—―‘’“”•…′€™●★☆☉☞♡《ＲＴ􏰀\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhiBIlmj-VK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(r'[‘’`´′]', \"'\", text_corpus)\n",
        "text_corpus = re.sub(r'[“”«»]', '\"', text_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmibaayLuVkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(\n",
        "    r\"[^ \\n<=>()*+-_,.'\\\":;?!…/0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#$£€%&@]\",\n",
        "    \"\",\n",
        "    text_corpus,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYQclWBBBjC",
        "colab_type": "code",
        "outputId": "321b2acc-6076-4633-e930-24ba1a227ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Length of all characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of all characters in text corpus - 93\n",
            "Characters: \n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz£…€\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSya_feJIxaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(text):\n",
        "    return keras.preprocessing.text.text_to_word_sequence(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdcX9_98TR29",
        "colab_type": "code",
        "outputId": "04349eba-4ecc-4b94-95bb-6f86d0b2cdd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_words = preprocess_text(text_corpus)\n",
        "print(f'We have total {len(text_words)} words and {len(text_corpus)} characters in tweets.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have total 581149 words and 3927715 characters in tweets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve2IiIneU-Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_vocabulary(word_list):\n",
        "    vocabulary = collections.Counter()\n",
        "    vocabulary.update(word_list)\n",
        "    return vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zvbo99RW8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = make_vocabulary(text_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcvuxf-Gynw5",
        "colab_type": "code",
        "outputId": "5ff913b1-83d2-40aa-8279-bcfb2a3d6146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vocabulary.most_common()[0:11]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tweetend', 31173),\n",
              " ('the', 17631),\n",
              " ('to', 11121),\n",
              " ('a', 9416),\n",
              " ('realdonaldtrump', 8719),\n",
              " ('is', 7916),\n",
              " ('you', 7895),\n",
              " ('and', 7318),\n",
              " ('in', 7077),\n",
              " ('of', 6604),\n",
              " ('i', 6511)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4GlsAazx5u",
        "colab_type": "code",
        "outputId": "0647d274-f147-4bac-b3fd-cbda6043f521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvnRfUbL0Ggb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_id = {word: index for index, word in enumerate(vocabulary)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNN5CkDs0KyV",
        "colab_type": "code",
        "outputId": "6638a128-cb51-422c-f2a7-8443b8eef91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for word in preprocess_text('Make America Great Again!'):\n",
        "    print(word_to_id.get(word) or 'Not available')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "267\n",
            "268\n",
            "56\n",
            "269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVC8ZsrW3D4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limiting the vocabulary to words detected 5 or more times in text corpus\n",
        "THRESHOLD = 5\n",
        "\n",
        "vocabulary = [word for word, count in vocabulary.most_common() if count >= THRESHOLD]\n",
        "vocabulary_size = len(vocabulary)\n",
        "n_oov_buckets = vocabulary_size // 10\n",
        "\n",
        "words = tf.constant(vocabulary)\n",
        "word_ids = tf.range(len(vocabulary), dtype=tf.int64)\n",
        "\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, n_oov_buckets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te6SQ9Tcy6Il",
        "colab_type": "code",
        "outputId": "239425b3-f7e1-412a-c58d-56971af421c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwH-IyGQNx_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_text(text):\n",
        "    return table.lookup(tf.constant(preprocess_text(text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YXHe6GZ_AwF",
        "colab_type": "code",
        "outputId": "d8717714-143b-46e5-fdb3-7028006cced7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode_text('Make America Great Again!')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=19, shape=(4,), dtype=int64, numpy=array([70, 65, 17, 89])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7vb5t6M8fDO",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Preprocessing - Reducing Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXNPvce87jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing tweets having at least one word not present in the vocabulary\n",
        "reduced_data = raw_data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlLeyzvoWuNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_df(tweet_text):\n",
        "    drop_tweet = max(encode_text(tweet_text).numpy()) < vocabulary_size\n",
        "    return drop_tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkjuOn5vXV1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_data['Leave'] = reduced_data['Text'].apply(reduce_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOtCxmoDYE9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_data = reduced_data[reduced_data['Leave']]\n",
        "reduced_data = reduced_data.drop(['Leave'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvmfUDE1YOJP",
        "colab_type": "code",
        "outputId": "f92a4a3f-f1c1-468d-cbe2-63ccd0085349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reduced_data.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Campaigning to win the Electoral College is mu...</td>\n",
              "      <td>2016-12-21 13:15:14</td>\n",
              "      <td>14906</td>\n",
              "      <td>3925</td>\n",
              "      <td>811560662853939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bill Clinton stated that I called him after th...</td>\n",
              "      <td>2016-12-20 13:03:59</td>\n",
              "      <td>67369</td>\n",
              "      <td>16962</td>\n",
              "      <td>811195441710764032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"@mike_pence: Congratulations to @RealDonaldTr...</td>\n",
              "      <td>2016-12-20 02:50:25</td>\n",
              "      <td>66605</td>\n",
              "      <td>14547</td>\n",
              "      <td>811041034323054592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"@Franklin_Graham: Congratulations to Presiden...</td>\n",
              "      <td>2016-12-20 02:46:01</td>\n",
              "      <td>44713</td>\n",
              "      <td>9659</td>\n",
              "      <td>811039925571354624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>We should tell China that we don't want the dr...</td>\n",
              "      <td>2016-12-18 00:59:25</td>\n",
              "      <td>62769</td>\n",
              "      <td>17611</td>\n",
              "      <td>810288321880555520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text  ...            Tweet ID\n",
              "2   Campaigning to win the Electoral College is mu...  ...  811560662853939200\n",
              "5   Bill Clinton stated that I called him after th...  ...  811195441710764032\n",
              "6   \"@mike_pence: Congratulations to @RealDonaldTr...  ...  811041034323054592\n",
              "7   \"@Franklin_Graham: Congratulations to Presiden...  ...  811039925571354624\n",
              "11  We should tell China that we don't want the dr...  ...  810288321880555520\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8DOo78YU6E",
        "colab_type": "code",
        "outputId": "01672add-f588-4410-aa4b-ab4e6bf764e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of rows in the dataset:', reduced_data.shape[0])\n",
        "print('Number of columns in the dataset:', reduced_data.shape[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 5490\n",
            "Number of columns in the dataset: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-DvYAChaiy7",
        "colab_type": "code",
        "outputId": "d53aaf88-8d36-4263-ea49-d62b98b95cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "text_corpus = \" \\n<TWEETEND>\\n \".join(reduced_data[text_col].values)\n",
        "print(text_corpus[:1000])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Campaigning to win the Electoral College is much more difficult & sophisticated than the popular vote. Hillary focused on the wrong states! \n",
            "<TWEETEND>\n",
            " Bill Clinton stated that I called him after the election. Wrong, he called me (with a very nice congratulations). He \"doesn't know much\" ... \n",
            "<TWEETEND>\n",
            " \"@mike_pence: Congratulations to @RealDonaldTrump; officially elected President of the United States today by the Electoral College!\" \n",
            "<TWEETEND>\n",
            " \"@Franklin_Graham: Congratulations to President-elect @realDonaldTrump--the electoral votes are in and it's official.\" Thank you Franklin! \n",
            "<TWEETEND>\n",
            " We should tell China that we don't want the drone they stole back.- let them keep it! \n",
            "<TWEETEND>\n",
            " Mobile, Alabama today at 3:00 P.M. Last rally of the year - \"THANK YOU ALABAMA AND THE SOUTH\" Biggest of all crowds expected, see you there! \n",
            "<TWEETEND>\n",
            " Last night in Orlando, Florida, was incredible - massive crowd - THANK YOU FLORIDA! Today at 3:00 P.M. I will be in Alabama for last rally! \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXEu5wiBb43A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(r'[‘’`´′]', \"'\", text_corpus)\n",
        "text_corpus = re.sub(r'[“”«»]', '\"', text_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32sFGi0b6sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(\n",
        "    r\"[^ \\n<=>()*+-_,.'\\\":;?!…/0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#$£€%&@]\",\n",
        "    \"\",\n",
        "    text_corpus,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_8YMSD7A5g0",
        "colab_type": "code",
        "outputId": "5ee32ffc-c6ac-495c-c56f-b1ca3dbc28ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Total of all different characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total of all different characters in text corpus - 87\n",
            "Characters: \n",
            " !\"#$%&'()+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zVXQ-DUcctx",
        "colab_type": "code",
        "outputId": "a9712f8a-4384-48aa-f2e3-ada696071ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_words = preprocess_text(text_corpus)\n",
        "print(f'We have {len(text_words)} words and {len(text_corpus)} characters left in reduced number of tweets.')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 105029 words and 648330 characters left in reduced number of tweets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxkSXbEo1mTY",
        "colab_type": "text"
      },
      "source": [
        "### ***Dataset Creation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIXtaPipKyDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQjVGF2PMPe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 64\n",
        "window_length = n_steps + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZu8NMhECF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data, vocabulary_size, window_length, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "    dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length, drop_remainder=True))\n",
        "    dataset = dataset.shuffle(math.ceil(len(data) / n_steps))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, -1:]), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.map(lambda xs, ys: (tf.one_hot(xs, depth=vocabulary_size), tf.squeeze(ys)), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIIXo4mrMvzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = encode_text(text_corpus)\n",
        "train_size = len(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejk2rb2TKcpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = make_dataset(train_data, vocabulary_size, window_length, BATCH_SIZE)\n",
        "train_data_steps = math.ceil(train_size / BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I5cnNDPNEYC",
        "colab_type": "code",
        "outputId": "ae94cd18-0ead-4635-98c0-bc89fa59a64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(256, 64, 6701), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(256,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myxconZ_PJjb",
        "colab_type": "code",
        "outputId": "9d88553c-a349-4b13-bafe-09f25bea7546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for xs, ys in train_dataset.take(1):\n",
        "    print(xs.shape, ys.shape)\n",
        "    print(xs[0].numpy().argmax(axis=-1))\n",
        "    print(ys[0].numpy())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 64, 6701) (256,)\n",
            "[ 143   76    1   91  137  232  435  129  106    2  574    3  518  569\n",
            " 4129    8    1 1022    9    1  493  165 4132   10   77   86   41    0\n",
            " 2002  822    1  433  381    5  390   11  170    0 3636  274 2668 4133\n",
            "    3   57 4840  106 4841    8    1  227   76    7  244 1089   19   18\n",
            " 1154  274 2339  103  208    1   91  137]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psdy2DX8wYN6",
        "colab_type": "text"
      },
      "source": [
        "## ***Exploring Different Model Architectures***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h96gdJY7hoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRaNg9vpYCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "LEARN_RATE = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqd8VHuwokj",
        "colab_type": "text"
      },
      "source": [
        "### ***RNN Model - Simple LSTM***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVTs5HNEvILW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_simple_lstm_model(\n",
        "    n_categories,\n",
        "    lstm_size,\n",
        "    lstm_dropout,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[None, n_categories])\n",
        "    lstm1_layer = keras.layers.LSTM(lstm_size, dropout=lstm_dropout, return_sequences=True)(input_layer)\n",
        "    lstm2_layer = keras.layers.LSTM(lstm_size, dropout=lstm_dropout)(lstm1_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(lstm2_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfMnoV3Mw-6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_simple_lstm_model(\n",
        "    n_categories=vocabulary_size,\n",
        "    lstm_size=256,\n",
        "    lstm_dropout=0.0,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TDvZ4PURFH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=LEARN_RATE),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpn-Hbb9RZl1",
        "colab_type": "code",
        "outputId": "f7632c28-8c0b-49d2-c255-6208e6051a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, None, 6701)]      0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, None, 256)         7124992   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6701)              1722157   \n",
            "=================================================================\n",
            "Total params: 9,373,485\n",
            "Trainable params: 9,372,973\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FmHEkKwReOR",
        "colab_type": "code",
        "outputId": "2a2a3407-2c04-47e0-995b-6e13cfd0bebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=train_dataset,\n",
        "    steps_per_epoch=train_data_steps,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5),\n",
        "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=13, restore_best_weights=True),\n",
        "        keras.callbacks.TerminateOnNaN(),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 127s 308ms/step - loss: 9.3271\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 8.2043\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 7.7444\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 7.1499\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 6.6042\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 6.2706\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.0498\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 5.8793\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 121s 293ms/step - loss: 5.7317\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 5.5951\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 5.4680\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 121s 294ms/step - loss: 5.3480\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 121s 293ms/step - loss: 5.2334\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 120s 293ms/step - loss: 5.1239\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 120s 293ms/step - loss: 5.0226\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 121s 294ms/step - loss: 4.9211\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 4.8235\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 4.7296\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 121s 293ms/step - loss: 4.6412\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 4.5519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SWmtrydUAkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    input_text = encode_text(text)\n",
        "    input_text = tf.one_hot(input_text, vocabulary_size)\n",
        "    input_text = tf.expand_dims(input_text, axis=0)\n",
        "    return input_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNAYHiLVUgW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_next_word(model, text, temperature=1):\n",
        "    prediction_input = preprocess(text)\n",
        "    prediction_probs = model.predict(prediction_input, steps=1)\n",
        "    rescaled_logits = tf.math.log(prediction_probs) / temperature\n",
        "    word_index = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "    word = vocabulary[tf.squeeze(word_index)]\n",
        "    return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tyy0wxkUj5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, text, n_words=10, temperature=1):\n",
        "    for _ in range(n_words):\n",
        "        text += f' {predict_next_word(model, text, temperature)}'\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5gv06zUoKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_samples(model, seed_text, n_words, temperatures):\n",
        "    for temperature in temperatures:\n",
        "        print(f'Temperature is set at {temperature:.0%}')\n",
        "        print(generate_text(model, seed_text, n_words=n_words, temperature=temperature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7h_SeYUtJQ",
        "colab_type": "code",
        "outputId": "7cfd52db-068f-4a0d-f958-fc566fb04cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend tweetend i i i be realdonaldtrump president president i i miss miss miss pageant pageant i am miss miss\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend tweetend i i realdonaldtrump president president i i agree i miss i miss miss miss pageant pageant i am\n",
            "Temperature is set at 100%\n",
            "Make America great again! tweetend tweetend i si wednesday president really seankesser support i treated i congratulations pays our wall pageant again i miss\n",
            "Temperature is set at 150%\n",
            "Make America great again! tweetend tweetend glennbeck choker mitt remember rumor realdonaldtrump i i didn't fold planes achievers miss apprentice 9 apprentice obama's miss\n",
            "Temperature is set at 200%\n",
            "Make America great again! tweetend obnoxious lyin' parade vattenfallgroup bump mrs due thedc ma prisoners i recommend pensacola ms 7 obnoxious lyin' wall miss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wewPowBBnHkP",
        "colab_type": "text"
      },
      "source": [
        "### ***RNN Model - Bidirectional LSTM***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPi-3QLedv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bidir_lstm_model(\n",
        "    n_categories,\n",
        "    lstm_size,\n",
        "    lstm_dropout,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[None, n_categories])\n",
        "    lstm1_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(lstm_size, dropout=lstm_dropout, return_sequences=True)\n",
        "    )(input_layer)\n",
        "    lstm2_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(lstm_size, dropout=lstm_dropout)\n",
        "    )(lstm1_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(lstm2_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QlYmqixnU5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_bidir_lstm_model(\n",
        "    n_categories=vocabulary_size,\n",
        "    lstm_size=256,\n",
        "    lstm_dropout=0.0,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eRkFpNMo2BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=LEARN_RATE),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KCapI3wo-9k",
        "colab_type": "code",
        "outputId": "b175ae88-321b-4b55-bc3a-08ce38767a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, None, 6701)]      0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 512)         14249984  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6701)              3437613   \n",
            "=================================================================\n",
            "Total params: 19,264,557\n",
            "Trainable params: 19,263,533\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY4KVyqopEF1",
        "colab_type": "code",
        "outputId": "8904f086-cc6b-4e2c-91c9-2ae9d8626885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=train_dataset,\n",
        "    steps_per_epoch=train_data_steps,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5),\n",
        "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=13, restore_best_weights=True),\n",
        "        keras.callbacks.TerminateOnNaN(),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 162s 394ms/step - loss: 9.8735\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 154s 375ms/step - loss: 8.0271\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 157s 381ms/step - loss: 7.4889\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 156s 379ms/step - loss: 7.0979\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 154s 375ms/step - loss: 6.7416\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 157s 381ms/step - loss: 6.4590\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 155s 377ms/step - loss: 6.2297\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 155s 377ms/step - loss: 6.0426\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 155s 376ms/step - loss: 5.8867\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 154s 375ms/step - loss: 5.7484\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 156s 379ms/step - loss: 5.6133\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 154s 374ms/step - loss: 5.4935\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 156s 380ms/step - loss: 5.3682\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 154s 375ms/step - loss: 5.2542\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 155s 377ms/step - loss: 5.1367\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 154s 376ms/step - loss: 5.0239\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 155s 378ms/step - loss: 4.9145\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 155s 377ms/step - loss: 4.8049\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 154s 374ms/step - loss: 4.6965\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 153s 372ms/step - loss: 4.5994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wItR9mjpdxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e3c34e5a-193d-4e82-b198-bf4e144dee0b"
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend s and s is of s is and are has has has has to should should has has been\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend s and s is is s of are deal has has has to has should has been has has\n",
            "Temperature is set at 100%\n",
            "Make America great again! tweetend and doesn't s and are is s and of should should has has has has been has has should\n",
            "Temperature is set at 150%\n",
            "Make America great again! tweetend s tweetend should doesn't has wants are and has has of doesn't has should no clinton are has has\n",
            "Temperature is set at 200%\n",
            "Make America great again! tweetend tweetend and sanders than s are has is of respect are is has should been should s to meaning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XN7RTyVxm8",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Wiki words 250 normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGCotpiTpuZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_text_dataset(data, window_length, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "    dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length, drop_remainder=True))\n",
        "    dataset = dataset.shuffle(math.ceil(len(data) / n_steps))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, -1:]), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.map(\n",
        "        lambda xs, ys: (tf.strings.reduce_join(xs, axis=1, separator=' '), table.lookup(tf.squeeze(ys))),\n",
        "        num_parallel_calls=AUTOTUNE,\n",
        "    )\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJOVNWlGX8OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data = tf.constant(text_words)\n",
        "text_data_size = len(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_FH_M70V2rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_dataset = make_text_dataset(text_data, window_length, BATCH_SIZE)\n",
        "text_data_steps = math.ceil(text_data_size / BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQNil82yvKhZ",
        "colab_type": "code",
        "outputId": "11f28034-4deb-4588-d15d-d8086162bb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "text_dataset.element_spec"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(256,), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(256,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQibuRnoXqv-",
        "colab_type": "code",
        "outputId": "d4a54c25-6b5d-473e-e922-71f1813097bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for xs, ys in text_dataset.take(1):\n",
        "    print(xs.shape, ys.shape)\n",
        "    print(xs[0])\n",
        "    print(ys[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256,) (256,)\n",
            "tf.Tensor(b'out to vote this election is far from over we are doing well but there is much time left go florida tweetend just out according to cnn utah officials report voting machine problems across entire country tweetend i will be watching the election results from trump tower in manhattan with my family and friends very exciting tweetend today we make america great again tweetend', shape=(), dtype=string)\n",
            "tf.Tensor(70, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_haQC3b6JCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hub_model(\n",
        "    model_url,\n",
        "    n_categories,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "    hub_layer = hub.KerasLayer(model_url)(input_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(hub_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbmcumA0JVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    epochs,\n",
        "    lrs=None,\n",
        "    optimizers=None,\n",
        "    verbose=1,\n",
        "):\n",
        "    if optimizers is None:\n",
        "        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\n",
        "\n",
        "    model.layers[0].trainable = False\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[0],\n",
        "    )\n",
        "    model.fit(\n",
        "        text_dataset,\n",
        "        steps_per_epoch=text_data_steps,\n",
        "        epochs=epochs[0],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "            keras.callbacks.TerminateOnNaN(),\n",
        "        ],\n",
        "        verbose=verbose,\n",
        "    )\n",
        "\n",
        "    model.layers[0].trainable = True\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[1],\n",
        "    )\n",
        "    history = model.fit(\n",
        "        text_dataset,\n",
        "        steps_per_epoch=text_data_steps,\n",
        "        epochs=epochs[1],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=13, restore_best_weights=True),\n",
        "            keras.callbacks.TerminateOnNaN(),\n",
        "        ],\n",
        "        verbose=verbose,\n",
        "    )\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsgR8D0042y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/Wiki-words-250-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPvLcRnLJHSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK8w1e4S5dlm",
        "colab_type": "code",
        "outputId": "4ceec1b3-f7a9-48eb-a226-37e623341103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 10.6368\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 9.8412\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 9.0863\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.7531\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.4402\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.9792\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.4898\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.1988\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 7.0539\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.9751\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.9301\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8959\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8731\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.8529\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8365\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.8218\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8076\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7949\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.7807\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7695\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7581\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.7483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UfYkRQPTGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_next_word(model, text, temperature=1):\n",
        "    prediction_input = tf.constant([text], dtype=tf.string)\n",
        "    prediction_probs = model.predict(prediction_input)\n",
        "    rescaled_logits = tf.math.log(prediction_probs) / temperature\n",
        "    word_index = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "    word = vocabulary[tf.squeeze(word_index)]\n",
        "    return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94v8BDU4O20p",
        "colab_type": "code",
        "outputId": "d83d2b49-6ed1-4d50-ce7c-5cd8bf146321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice\n",
            "Temperature is set at 50%\n",
            "Make America great again! realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice\n",
            "Temperature is set at 100%\n",
            "Make America great again! virginia barackobama also celebapprentice actual watching uncle 2012 please scotland now never please is such learn i'll south i realdonaldtrump\n",
            "Temperature is set at 150%\n",
            "Make America great again! state rubio multi 13th in server as the that tweets nydn michelle just i'll thanks monday celebapprentice towards fit known\n",
            "Temperature is set at 200%\n",
            "Make America great again! palin because non sink cleveland uruguay 2010 superb http newtgingrich hate that unfairly fathers doug no less www1 should toughness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvUCLNSCyRUA",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Wiki words 500 normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qfeDPncyVi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/Wiki-words-500-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1dMlJh1yYK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0F3gLoVyY3S",
        "colab_type": "code",
        "outputId": "89c5cff0-fd8b-4382-e27a-bacdc767ede1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 12.3690\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 10.7673\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 9.3438\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.7504\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.1859\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.5578\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.2170\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.0773\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.0081\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 6.9667\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.9377\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9123\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8939\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.8729\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8543\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8384\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8221\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8081\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7956\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7820\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7709\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTuQslA0yagR",
        "colab_type": "code",
        "outputId": "05c15523-ac7c-43af-e1d8-dc8b2b906da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice\n",
            "Temperature is set at 50%\n",
            "Make America great again! celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice\n",
            "Temperature is set at 100%\n",
            "Make America great again! won't realdonaldtrump club 5 tremendous at like always ask happy our says we doral celebapprentice a prix stern marble loan\n",
            "Temperature is set at 150%\n",
            "Make America great again! economic he ally is equity c expansion really allies girlfriend hillary gas children's task already about numbers aplemonlemon everyone can\n",
            "Temperature is set at 200%\n",
            "Make America great again! referring sooooo inspiring she main misleading back almost rollout winning wow socialist ran primaries surgery trip packed comey 15th dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTRPjcYazdbz",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - nnlm 50 dims normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iA4r0qmzemZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50-with-normalization/1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHCnQZUVzgyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8lQ2GezgRG",
        "colab_type": "code",
        "outputId": "cd79f6b9-7eec-47ae-e234-e4fd342c8eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 21s 50ms/step - loss: 9.1809\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 9.0152\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 20s 50ms/step - loss: 8.8381\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 20s 49ms/step - loss: 8.7376\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.6439\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.5155\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.3323\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 20s 49ms/step - loss: 8.0885\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 7.8079\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.5400\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.3282\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.1741\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.0635\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9851\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9276\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8844\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8496\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8227\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8038\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.7833\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 6.7674\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMXZqOjVzfgv",
        "colab_type": "code",
        "outputId": "7fb2dd02-4560-48b5-95dd-257898d6eb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend tweetend on tweetend the be the the the tweetend the the of the best the the of the best\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend tweetend on that tweetend the is and on in show the tweetend tweetend i the the new i enjoy\n",
            "Temperature is set at 100%\n",
            "Make America great again! tweetend towers more 30 not sr i'm for day fix pm thomas business star' respectful snowden i lateshow cnbc know\n",
            "Temperature is set at 150%\n",
            "Make America great again! bangor stand the years thanks trump al my famous epa dj aides lawrence 'president 000 pure homeland face realdonaldtrump electric\n",
            "Temperature is set at 200%\n",
            "Make America great again! dealmaker thank springfield would salmond form personal hurts representatives queen achieve face sharks doesn't earn apart egypt costs pastors downside\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywD4AIQqmfNH",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - nnlm 128 dims normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLzJcopYRMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHNXM-CsnFr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y83dDEwtnHgP",
        "colab_type": "code",
        "outputId": "8bb12583-710f-420a-e505-3b0144ba8e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 9.7603\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 9.3512\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 23s 55ms/step - loss: 8.9415\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.7425\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.5559\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.2786\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.8916\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.4979\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.2254\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.0642\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9638\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9016\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8568\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 6.8243\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.7979\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7778\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7589\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.7431\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7269\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7154\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7019\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.6898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv1rYF8JnnTb",
        "colab_type": "code",
        "outputId": "ad609e5b-70d8-4afa-94fd-0760d24a495e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend the tweetend realdonaldtrump realdonaldtrump realdonaldtrump realdonaldtrump realdonaldtrump tweetend realdonaldtrump realdonaldtrump realdonaldtrump realdonaldtrump trump realdonaldtrump realdonaldtrump realdonaldtrump trump trump trump\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend you is tweetend the is great and tweetend on will be and the a if the the to more\n",
            "Temperature is set at 100%\n",
            "Make America great again! show run tweetend for to bernie as a will if i tx your to people of without j again settle\n",
            "Temperature is set at 150%\n",
            "Make America great again! never could calm 8 believe love wasserman xx nc brilliant tweetend guide tweetend carolina instagram at will apprenticenbc achieve draw\n",
            "Temperature is set at 200%\n",
            "Make America great again! mid bought reduce tweetend conde trumpdoral currently caught jewish sp interested will spent than congratulations m really going hammer intelligence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-rYBaD4_PF",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Google News Swivel 20 dims***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7V7MFI2nzBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbJ3j_f5B5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.0,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM1vDDNB5Mlu",
        "colab_type": "code",
        "outputId": "c627f632-8917-4253-88fc-9f47cf39029b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.9549\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.8824\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.7969\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.7360\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.6797\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.6103\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.5189\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.4005\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.2538\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.0823\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.8883\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 7.6867\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.4935\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.3257\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.1920\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.0892\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.0142\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.9539\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9073\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8725\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8433\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJi3bnjs5TSf",
        "colab_type": "code",
        "outputId": "5c041e70-8156-46b9-bf26-bcb840d77f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! the tweetend tweetend the tweetend the to tweetend the the tweetend tweetend tweetend tweetend the tweetend tweetend the tweetend tweetend\n",
            "Temperature is set at 50%\n",
            "Make America great again! on that to the you tweetend you the the tweetend the be tweetend be at will i the to tweetend\n",
            "Temperature is set at 100%\n",
            "Make America great again! get why ebola are helping marco i tweetend kravis soldier house extend will way electric company smart always by totally\n",
            "Temperature is set at 150%\n",
            "Make America great again! k amazing years dept www1 conrad donate veterans la 11746… polling linda with she any was aware hopeful which seem\n",
            "Temperature is set at 200%\n",
            "Make America great again! stuck stupidly drilling files himself championship snurk total amazing mind 00am iq exec twisting franklin monday joniernst crazy seth very\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}