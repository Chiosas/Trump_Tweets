{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trump Tweets - Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiosas/Trump_Tweets/blob/master/Trump_Tweets_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBZ5O1Rt7k6U",
        "colab_type": "text"
      },
      "source": [
        "## ***Initial Setup***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70QsN6iA7mcj",
        "colab_type": "text"
      },
      "source": [
        "### ***Environment Setup***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8pw5PhZ7IAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHkoT1M7vou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_name = 'Trump_Tweets'\n",
        "DATA_DIR = Path(f'data/{dir_name}')\n",
        "MODEL_DIR = Path(f'model/{dir_name}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiqtZbSh74fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "FIRST_RUN = not os.path.exists(str(MODEL_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ2vw6oq7-xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not IN_COLAB:\n",
        "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jopveXb8Dz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FIRST_RUN:\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "if IN_COLAB and FIRST_RUN:\n",
        "    !pip install -q --upgrade scikit-optimize\n",
        "    !pip install -q -U --pre efficientnet\n",
        "    # !pip install -q -U tensorflow-datasets\n",
        "    !pip install -q -U --no-deps tensorflow-addons~=0.6\n",
        "    !pip install -q -U tensorflow_hub\n",
        "    !pip install -q -U git+https://github.com/huggingface/transformers    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W7gJzhy8tPs",
        "colab_type": "text"
      },
      "source": [
        "### ***Kaggle Setup***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpKDbei-8laR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_kaggle():\n",
        "    x = !ls kaggle.json\n",
        "    assert x == ['kaggle.json'], 'Upload kaggle.json'\n",
        "    !mkdir /root/.kaggle\n",
        "    !mv kaggle.json /root/.kaggle\n",
        "    !chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO_OW_I485LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure you've uploaded 'kaggle.json' file into Colab\n",
        "if IN_COLAB and FIRST_RUN:\n",
        "    setup_kaggle()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itkj3QMy9Bh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1qsCvUI9HTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IN_COLAB and FIRST_RUN:\n",
        "    kaggle.api.authenticate()\n",
        "    kaggle.api.dataset_download_files(\n",
        "        dataset='austinvernsonger/donaldtrumptweets',\n",
        "        path=DATA_DIR,\n",
        "        unzip=True,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3jTal2B-H8D",
        "colab_type": "text"
      },
      "source": [
        "### ***Importing Dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k08UgIL9gbL",
        "colab_type": "code",
        "outputId": "4a592604-8300-4fac-a3aa-b37b311e8ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ett300eZ-SwC",
        "colab_type": "code",
        "outputId": "b84fd94c-7e7b-4632-f72f-1c5850a0b6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from imports import *\n",
        "\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAI_-l4-Xr-",
        "colab_type": "code",
        "outputId": "fac815ee-a98b-49c0-8b46-4d5010bb3804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr33nFIH-dEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FIRST_RUN:\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqr62av-h4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QByFPgb7-o1B",
        "colab_type": "text"
      },
      "source": [
        "## ***Data Description***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3fAYoe-25U",
        "colab_type": "text"
      },
      "source": [
        "### **Content**\n",
        "\n",
        "![Trump](https://cdn.cnn.com/cnnnext/dam/assets/180925135532-gfx-twitter-donald-trump-tweet-exlarge-169.jpg)\n",
        "\n",
        "This dataset is a collection of more than 30,000 Donald Trump tweets, dating from 2009 to 2016.\n",
        "\n",
        "The columns of the data file are:\n",
        "\n",
        "* Text — full message posted on Twitter,\n",
        "* Date — date when Twitter message was posted,\n",
        "* Favorites — number of times Twitter message was marked as favorite by the other users,\n",
        "* Retweets — number of times Twitter message was re-posted or shared by the other users,\n",
        "* Tweet ID — ID of Twitter message.\n",
        "\n",
        "\n",
        "We will use this dataset to create a word-level text generator using a pretrained architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6P2k7ur_B1g",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Exploration***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY4PVmqjhGA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the data from the file\n",
        "raw_data = pd.read_csv(DATA_DIR/'data.csv', low_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz3qy-yyhRac",
        "colab_type": "code",
        "outputId": "7382efed-0800-4295-bbc1-b330cd91247e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of rows in the dataset:', raw_data.shape[0])\n",
        "print('Number of columns in the dataset:', raw_data.shape[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 31175\n",
            "Number of columns in the dataset: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR0iUS5nhZji",
        "colab_type": "code",
        "outputId": "e5775dc9-0752-487a-eb85-ca77d3f5de26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "raw_data.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31175 entries, 0 to 31174\n",
            "Data columns (total 5 columns):\n",
            "Text         31174 non-null object\n",
            "Date         31175 non-null object\n",
            "Favorites    31175 non-null int64\n",
            "Retweets     31175 non-null int64\n",
            "Tweet ID     31175 non-null int64\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFwlkllhhfDY",
        "colab_type": "code",
        "outputId": "c6e24ce3-a7fe-4d30-e28d-bde267cb497e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "raw_data.describe(include='all')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31174</td>\n",
              "      <td>31175</td>\n",
              "      <td>31175.000000</td>\n",
              "      <td>31175.000000</td>\n",
              "      <td>3.117500e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>31057</td>\n",
              "      <td>31174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>MAKE AMERICA GREAT AGAIN!</td>\n",
              "      <td>2016-01-14 05:45:41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3167.715926</td>\n",
              "      <td>1255.764555</td>\n",
              "      <td>4.654273e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11655.175669</td>\n",
              "      <td>4638.563418</td>\n",
              "      <td>1.789587e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.698309e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.185713e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>4.738490e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>643.000000</td>\n",
              "      <td>613.000000</td>\n",
              "      <td>6.108192e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>639223.000000</td>\n",
              "      <td>349873.000000</td>\n",
              "      <td>8.115643e+17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Text  ...      Tweet ID\n",
              "count                       31174  ...  3.117500e+04\n",
              "unique                      31057  ...           NaN\n",
              "top     MAKE AMERICA GREAT AGAIN!  ...           NaN\n",
              "freq                           11  ...           NaN\n",
              "mean                          NaN  ...  4.654273e+17\n",
              "std                           NaN  ...  1.789587e+17\n",
              "min                           NaN  ...  1.698309e+09\n",
              "25%                           NaN  ...  3.185713e+17\n",
              "50%                           NaN  ...  4.738490e+17\n",
              "75%                           NaN  ...  6.108192e+17\n",
              "max                           NaN  ...  8.115643e+17\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXBDGNsXG5cV",
        "colab_type": "code",
        "outputId": "6fd9276a-8bf3-4825-e9f3-b3ff2ddbb198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "raw_data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have not heard any of the pundits or comment...</td>\n",
              "      <td>2016-12-21 13:29:38</td>\n",
              "      <td>14755</td>\n",
              "      <td>4055</td>\n",
              "      <td>811564284706689024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I would have done even better in the election,...</td>\n",
              "      <td>2016-12-21 13:24:29</td>\n",
              "      <td>11129</td>\n",
              "      <td>2789</td>\n",
              "      <td>811562990285848576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Campaigning to win the Electoral College is mu...</td>\n",
              "      <td>2016-12-21 13:15:14</td>\n",
              "      <td>14906</td>\n",
              "      <td>3925</td>\n",
              "      <td>811560662853939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes, it is true - Carlos Slim, the great busin...</td>\n",
              "      <td>2016-12-20 20:27:57</td>\n",
              "      <td>51424</td>\n",
              "      <td>12578</td>\n",
              "      <td>811307169043849216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>especially how to get people, even with an unl...</td>\n",
              "      <td>2016-12-20 13:09:18</td>\n",
              "      <td>35699</td>\n",
              "      <td>8008</td>\n",
              "      <td>811196778779463684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...            Tweet ID\n",
              "0  I have not heard any of the pundits or comment...  ...  811564284706689024\n",
              "1  I would have done even better in the election,...  ...  811562990285848576\n",
              "2  Campaigning to win the Electoral College is mu...  ...  811560662853939200\n",
              "3  Yes, it is true - Carlos Slim, the great busin...  ...  811307169043849216\n",
              "4  especially how to get people, even with an unl...  ...  811196778779463684\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jxy9SFo0MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoyFeX4ppicZ",
        "colab_type": "code",
        "outputId": "91cbd043-d50c-4a79-b284-a0461e333120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "raw_data.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31174 entries, 0 to 31174\n",
            "Data columns (total 5 columns):\n",
            "Text         31174 non-null object\n",
            "Date         31174 non-null object\n",
            "Favorites    31174 non-null int64\n",
            "Retweets     31174 non-null int64\n",
            "Tweet ID     31174 non-null int64\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM89EsBumorJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_col = 'Text'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SosGMaOwtXFQ",
        "colab_type": "text"
      },
      "source": [
        "## ***Data Preparation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9cgd7nuO0C",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Preprocessing - Vocabulary***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0O-6SwWondv",
        "colab_type": "code",
        "outputId": "8b02d2b4-45e6-48f6-fb4d-24566ce047e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "text_corpus = \" \\n<TWEETEND>\\n \".join(raw_data[text_col].values)\n",
        "print(text_corpus[:1000])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have not heard any of the pundits or commentators discussing the fact that I spent FAR LESS MONEY on the win than Hillary on the loss! \n",
            "<TWEETEND>\n",
            " I would have done even better in the election, if that is possible, if the winner was based on popular vote - but would campaign differently \n",
            "<TWEETEND>\n",
            " Campaigning to win the Electoral College is much more difficult & sophisticated than the popular vote. Hillary focused on the wrong states! \n",
            "<TWEETEND>\n",
            " Yes, it is true - Carlos Slim, the great businessman from Mexico, called me about getting together for a meeting. We met, HE IS A GREAT GUY! \n",
            "<TWEETEND>\n",
            " especially how to get people, even with an unlimited budget, out to vote in the vital swing states ( and more). They focused on wrong states \n",
            "<TWEETEND>\n",
            " Bill Clinton stated that I called him after the election. Wrong, he called me (with a very nice congratulations). He \"doesn't know much\" ... \n",
            "<TWEETEND>\n",
            " \"@mike_pence: Congratulations to @RealDonaldTrump; officially elected President o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUP0CavQs3ig",
        "colab_type": "code",
        "outputId": "a0c0443b-a17f-4310-97b1-76587974f38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Length of all characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of all characters in text corpus - 137\n",
            "Characters: \n",
            "\r !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz{|}~ £«®´º»Éèéíïñıĺ​‎‏–—―‘’“”•…′€™●★☆☉☞♡《ＲＴ􏰀\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhiBIlmj-VK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(r'[‘’`´′]', \"'\", text_corpus)\n",
        "text_corpus = re.sub(r'[“”«»]', '\"', text_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmibaayLuVkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(\n",
        "    r\"[^ \\n<=>()*+-_,.'\\\":;?!…/0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#$£€%&@]\",\n",
        "    \"\",\n",
        "    text_corpus,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYQclWBBBjC",
        "colab_type": "code",
        "outputId": "91b1604e-3311-441a-fe59-07b76d8dc7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Length of all characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of all characters in text corpus - 93\n",
            "Characters: \n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz£…€\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSya_feJIxaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(text):\n",
        "    return keras.preprocessing.text.text_to_word_sequence(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdcX9_98TR29",
        "colab_type": "code",
        "outputId": "f2e75e5c-e3e7-469f-920c-a72b0102ba08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_words = preprocess_text(text_corpus)\n",
        "print(f'We have total {len(text_words)} words and {len(text_corpus)} characters in tweets.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have total 581149 words and 3927715 characters in tweets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve2IiIneU-Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_vocabulary(word_list):\n",
        "    vocabulary = collections.Counter()\n",
        "    vocabulary.update(word_list)\n",
        "    return vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zvbo99RW8LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = make_vocabulary(text_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcvuxf-Gynw5",
        "colab_type": "code",
        "outputId": "94783fe7-7db4-4ed7-b9d2-c3015e85ec72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vocabulary.most_common()[0:11]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tweetend', 31173),\n",
              " ('the', 17631),\n",
              " ('to', 11121),\n",
              " ('a', 9416),\n",
              " ('realdonaldtrump', 8719),\n",
              " ('is', 7916),\n",
              " ('you', 7895),\n",
              " ('and', 7318),\n",
              " ('in', 7077),\n",
              " ('of', 6604),\n",
              " ('i', 6511)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4GlsAazx5u",
        "colab_type": "code",
        "outputId": "beb0b687-81da-4d31-bbd7-fcd188bd3b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvnRfUbL0Ggb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_id = {word: index for index, word in enumerate(vocabulary)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNN5CkDs0KyV",
        "colab_type": "code",
        "outputId": "47d30aaa-4b22-48db-cc0e-4f64f2c49b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for word in preprocess_text('Make America Great Again!'):\n",
        "    print(word_to_id.get(word) or 'Not available')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "267\n",
            "268\n",
            "56\n",
            "269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVC8ZsrW3D4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limiting the vocabulary to words detected 5 or more times in text corpus\n",
        "THRESHOLD = 5\n",
        "\n",
        "vocabulary = [word for word, count in vocabulary.most_common() if count >= THRESHOLD]\n",
        "vocabulary_size = len(vocabulary)\n",
        "n_oov_buckets = vocabulary_size // 10\n",
        "\n",
        "words = tf.constant(vocabulary)\n",
        "word_ids = tf.range(len(vocabulary), dtype=tf.int64)\n",
        "\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, n_oov_buckets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te6SQ9Tcy6Il",
        "colab_type": "code",
        "outputId": "b49fe0cd-57da-436c-de49-f8e4857addb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwH-IyGQNx_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_text(text):\n",
        "    return table.lookup(tf.constant(preprocess_text(text)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YXHe6GZ_AwF",
        "colab_type": "code",
        "outputId": "e26118d9-02bf-4fd1-cb5c-c77f310f9458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode_text('Make America Great Again!')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=19, shape=(4,), dtype=int64, numpy=array([70, 65, 17, 89])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7vb5t6M8fDO",
        "colab_type": "text"
      },
      "source": [
        "### ***Data Preprocessing - Reducing Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXNPvce87jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing tweets having at least one word not present in the vocabulary\n",
        "reduced_data = raw_data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlLeyzvoWuNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_df(tweet_text):\n",
        "    drop_tweet = max(encode_text(tweet_text).numpy()) < vocabulary_size\n",
        "    return drop_tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkjuOn5vXV1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_data['Leave'] = reduced_data['Text'].apply(reduce_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOtCxmoDYE9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_data = reduced_data[reduced_data['Leave']]\n",
        "reduced_data = reduced_data.drop(['Leave'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvmfUDE1YOJP",
        "colab_type": "code",
        "outputId": "2573efd7-a7d4-4a72-eee1-0127f2ed0842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "reduced_data.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Date</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Tweet ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Campaigning to win the Electoral College is mu...</td>\n",
              "      <td>2016-12-21 13:15:14</td>\n",
              "      <td>14906</td>\n",
              "      <td>3925</td>\n",
              "      <td>811560662853939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bill Clinton stated that I called him after th...</td>\n",
              "      <td>2016-12-20 13:03:59</td>\n",
              "      <td>67369</td>\n",
              "      <td>16962</td>\n",
              "      <td>811195441710764032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"@mike_pence: Congratulations to @RealDonaldTr...</td>\n",
              "      <td>2016-12-20 02:50:25</td>\n",
              "      <td>66605</td>\n",
              "      <td>14547</td>\n",
              "      <td>811041034323054592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"@Franklin_Graham: Congratulations to Presiden...</td>\n",
              "      <td>2016-12-20 02:46:01</td>\n",
              "      <td>44713</td>\n",
              "      <td>9659</td>\n",
              "      <td>811039925571354624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>We should tell China that we don't want the dr...</td>\n",
              "      <td>2016-12-18 00:59:25</td>\n",
              "      <td>62769</td>\n",
              "      <td>17611</td>\n",
              "      <td>810288321880555520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text  ...            Tweet ID\n",
              "2   Campaigning to win the Electoral College is mu...  ...  811560662853939200\n",
              "5   Bill Clinton stated that I called him after th...  ...  811195441710764032\n",
              "6   \"@mike_pence: Congratulations to @RealDonaldTr...  ...  811041034323054592\n",
              "7   \"@Franklin_Graham: Congratulations to Presiden...  ...  811039925571354624\n",
              "11  We should tell China that we don't want the dr...  ...  810288321880555520\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr8DOo78YU6E",
        "colab_type": "code",
        "outputId": "9aaae820-f8d8-475d-ed74-ceacf0e570b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of rows in the dataset:', reduced_data.shape[0])\n",
        "print('Number of columns in the dataset:', reduced_data.shape[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the dataset: 5490\n",
            "Number of columns in the dataset: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-DvYAChaiy7",
        "colab_type": "code",
        "outputId": "921f64a1-5f4d-4024-ebff-808a440a8a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "text_corpus = \" \\n<TWEETEND>\\n \".join(reduced_data[text_col].values)\n",
        "print(text_corpus[:1000])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Campaigning to win the Electoral College is much more difficult & sophisticated than the popular vote. Hillary focused on the wrong states! \n",
            "<TWEETEND>\n",
            " Bill Clinton stated that I called him after the election. Wrong, he called me (with a very nice congratulations). He \"doesn't know much\" ... \n",
            "<TWEETEND>\n",
            " \"@mike_pence: Congratulations to @RealDonaldTrump; officially elected President of the United States today by the Electoral College!\" \n",
            "<TWEETEND>\n",
            " \"@Franklin_Graham: Congratulations to President-elect @realDonaldTrump--the electoral votes are in and it's official.\" Thank you Franklin! \n",
            "<TWEETEND>\n",
            " We should tell China that we don't want the drone they stole back.- let them keep it! \n",
            "<TWEETEND>\n",
            " Mobile, Alabama today at 3:00 P.M. Last rally of the year - \"THANK YOU ALABAMA AND THE SOUTH\" Biggest of all crowds expected, see you there! \n",
            "<TWEETEND>\n",
            " Last night in Orlando, Florida, was incredible - massive crowd - THANK YOU FLORIDA! Today at 3:00 P.M. I will be in Alabama for last rally! \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXEu5wiBb43A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(r'[‘’`´′]', \"'\", text_corpus)\n",
        "text_corpus = re.sub(r'[“”«»]', '\"', text_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32sFGi0b6sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_corpus = re.sub(\n",
        "    r\"[^ \\n<=>()*+-_,.'\\\":;?!…/0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#$£€%&@]\",\n",
        "    \"\",\n",
        "    text_corpus,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_8YMSD7A5g0",
        "colab_type": "code",
        "outputId": "2c896040-da0d-4027-f532-fb09eb04285d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "all_chars = \"\".join(sorted(set(text_corpus)))\n",
        "print(f'Total of all different characters in text corpus - {len(all_chars)}\\nCharacters:', all_chars)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total of all different characters in text corpus - 87\n",
            "Characters: \n",
            " !\"#$%&'()+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz…\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zVXQ-DUcctx",
        "colab_type": "code",
        "outputId": "e99524a1-52af-4a09-b572-39cdec35ace8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_words = preprocess_text(text_corpus)\n",
        "print(f'We have {len(text_words)} words and {len(text_corpus)} characters left in reduced number of tweets.')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 105029 words and 648330 characters left in reduced number of tweets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxkSXbEo1mTY",
        "colab_type": "text"
      },
      "source": [
        "### ***Dataset Creation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIXtaPipKyDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQjVGF2PMPe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 64\n",
        "window_length = n_steps + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZu8NMhECF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data, vocabulary_size, window_length, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "    dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length, drop_remainder=True))\n",
        "    dataset = dataset.shuffle(math.ceil(len(data) / n_steps))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, -1:]), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.map(lambda xs, ys: (tf.one_hot(xs, depth=vocabulary_size), tf.squeeze(ys)), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIIXo4mrMvzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = encode_text(text_corpus)\n",
        "train_size = len(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejk2rb2TKcpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = make_dataset(train_data, vocabulary_size, window_length, BATCH_SIZE)\n",
        "train_data_steps = math.ceil(train_size / BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I5cnNDPNEYC",
        "colab_type": "code",
        "outputId": "4895c8ee-f681-4311-e199-a94bd9f703b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_dataset.element_spec"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(256, 64, 6701), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(256,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myxconZ_PJjb",
        "colab_type": "code",
        "outputId": "ebee9fbf-c40d-4e04-9588-6a7a06c1afa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for xs, ys in train_dataset.take(1):\n",
        "    print(xs.shape, ys.shape)\n",
        "    print(xs[0].numpy().argmax(axis=-1))\n",
        "    print(ys[0].numpy())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 64, 6701) (256,)\n",
            "[1601    8 2499   37  110    1  145   88    1  314  213  511   32    3\n",
            "   83  151    0   10  630 3165    9 2277  740  149  269  121  149   19\n",
            "    5    3  338   68 2588 1134   96  248 1281   22   37 5316   72   11\n",
            "   81    0 3166 1558   18   15  447    2 1792  120   49   10  742    2\n",
            " 4136   67    1 3298 3021 2187    2   70]\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psdy2DX8wYN6",
        "colab_type": "text"
      },
      "source": [
        "## ***Exploring Different Model Architectures***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h96gdJY7hoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRaNg9vpYCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "LEARN_RATE = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqd8VHuwokj",
        "colab_type": "text"
      },
      "source": [
        "### ***RNN Model - Simple LSTM***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVTs5HNEvILW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_simple_lstm_model(\n",
        "    n_categories,\n",
        "    lstm_size,\n",
        "    lstm_dropout,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[None, n_categories])\n",
        "    lstm1_layer = keras.layers.LSTM(lstm_size, dropout=lstm_dropout, return_sequences=True)(input_layer)\n",
        "    lstm2_layer = keras.layers.LSTM(lstm_size, dropout=lstm_dropout)(lstm1_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(lstm2_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfMnoV3Mw-6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_simple_lstm_model(\n",
        "    n_categories=vocabulary_size,\n",
        "    lstm_size=256,\n",
        "    lstm_dropout=0.2,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TDvZ4PURFH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=LEARN_RATE),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpn-Hbb9RZl1",
        "colab_type": "code",
        "outputId": "c02803c9-c517-482c-f58d-9c5f5eaa42fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 6701)]      0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 256)         7124992   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6701)              1722157   \n",
            "=================================================================\n",
            "Total params: 9,373,485\n",
            "Trainable params: 9,372,973\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FmHEkKwReOR",
        "colab_type": "code",
        "outputId": "5acad77a-f783-4ae0-e387-3e277b87586f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=train_dataset,\n",
        "    steps_per_epoch=train_data_steps,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5),\n",
        "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=13, restore_best_weights=True),\n",
        "        keras.callbacks.TerminateOnNaN(),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 127s 310ms/step - loss: 9.4130\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 8.4044\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 8.0799\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 7.7262\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 7.3122\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 6.9597\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 122s 298ms/step - loss: 6.7093\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.5399\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 122s 297ms/step - loss: 6.4075\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.3027\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.2189\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 6.1459\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.0768\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 6.0120\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 121s 294ms/step - loss: 5.9519\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 5.9024\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 121s 295ms/step - loss: 5.8443\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 121s 294ms/step - loss: 5.7916\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 122s 296ms/step - loss: 5.7384\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 121s 294ms/step - loss: 5.6937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SWmtrydUAkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    input_text = encode_text(text)\n",
        "    input_text = tf.one_hot(input_text, vocabulary_size)\n",
        "    input_text = tf.expand_dims(input_text, axis=0)\n",
        "    return input_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNAYHiLVUgW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_next_word(model, text, temperature=1):\n",
        "    prediction_input = preprocess(text)\n",
        "    prediction_probs = model.predict(prediction_input, steps=1)\n",
        "    rescaled_logits = tf.math.log(prediction_probs) / temperature\n",
        "    word_index = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "    word = vocabulary[tf.squeeze(word_index)]\n",
        "    return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tyy0wxkUj5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, text, n_words=10, temperature=1):\n",
        "    for _ in range(n_words):\n",
        "        text += f' {predict_next_word(model, text, temperature)}'\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5gv06zUoKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_samples(model, seed_text, n_words, temperatures):\n",
        "    for temperature in temperatures:\n",
        "        print(f'Temperature is set at {temperature:.0%}')\n",
        "        print(generate_text(model, seed_text, n_words=n_words, temperature=temperature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY7h_SeYUtJQ",
        "colab_type": "code",
        "outputId": "07303364-4c4b-47f0-85b4-3b9d4e2baa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend tweetend s s s too s tweetend they doesn't us us our jobs jobs we are our country and\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend tweetend s tweetend us s s too us they they are us us they are them we have their\n",
            "Temperature is set at 100%\n",
            "Make America great again! tweetend tweetend too s action they s us jobs but tweetend mitt can pac our edition tom every stupid really\n",
            "Temperature is set at 150%\n",
            "Make America great again! or tweetend s they too him too him no he's them tweetend clewandowski timing sending over restoring people now fortune\n",
            "Temperature is set at 200%\n",
            "Make America great again! tweetend tweetend tweetend greatly who execs confident us resonate protect makes ernie bobbyjindal determination than patrol comment revealed sixteenchicago election\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wewPowBBnHkP",
        "colab_type": "text"
      },
      "source": [
        "### ***RNN Model - Bidirectional LSTM***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPi-3QLedv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bidir_lstm_model(\n",
        "    n_categories,\n",
        "    lstm_size,\n",
        "    lstm_dropout,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[None, n_categories])\n",
        "    lstm1_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(lstm_size, dropout=lstm_dropout, return_sequences=True)\n",
        "    )(input_layer)\n",
        "    lstm2_layer = keras.layers.Bidirectional(\n",
        "        keras.layers.LSTM(lstm_size, dropout=lstm_dropout)\n",
        "    )(lstm1_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(lstm2_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QlYmqixnU5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_bidir_lstm_model(\n",
        "    n_categories=vocabulary_size,\n",
        "    lstm_size=256,\n",
        "    lstm_dropout=0.2,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eRkFpNMo2BT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.sparse_categorical_crossentropy,\n",
        "    optimizer=keras.optimizers.Adam(lr=LEARN_RATE),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KCapI3wo-9k",
        "colab_type": "code",
        "outputId": "c6eb588a-ac32-4cfd-e5d2-68ce8639a716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, 6701)]      0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 512)         14249984  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6701)              3437613   \n",
            "=================================================================\n",
            "Total params: 19,264,557\n",
            "Trainable params: 19,263,533\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY4KVyqopEF1",
        "colab_type": "code",
        "outputId": "77592aab-6c4f-4f33-cb24-d04fb3055c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=train_dataset,\n",
        "    steps_per_epoch=train_data_steps,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=5),\n",
        "        keras.callbacks.EarlyStopping(monitor=\"loss\", patience=13, restore_best_weights=True),\n",
        "        keras.callbacks.TerminateOnNaN(),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 168s 408ms/step - loss: 10.0055\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 160s 390ms/step - loss: 8.3155\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 161s 392ms/step - loss: 7.9273\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 161s 391ms/step - loss: 7.5158\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 160s 388ms/step - loss: 7.1364\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 161s 392ms/step - loss: 6.8425\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 160s 389ms/step - loss: 6.6200\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 161s 392ms/step - loss: 6.4591\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 161s 392ms/step - loss: 6.3303\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 160s 390ms/step - loss: 6.2275\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 160s 389ms/step - loss: 6.1259\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 159s 387ms/step - loss: 6.0331\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 160s 389ms/step - loss: 5.9518\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 159s 388ms/step - loss: 5.8749\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 160s 388ms/step - loss: 5.7982\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 160s 390ms/step - loss: 5.7302\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 160s 390ms/step - loss: 5.6546\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 159s 387ms/step - loss: 5.5866\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 159s 386ms/step - loss: 5.5317\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 160s 390ms/step - loss: 5.4604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wItR9mjpdxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "86834f1c-8489-4cd1-d98f-45ec18b2ea4a"
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! us us us us else don't know tweetend obama is for the new york and it and the people and\n",
            "Temperature is set at 50%\n",
            "Make America great again! us us us us too too long or we need tweetend to our great and this and the problem tweetend\n",
            "Temperature is set at 100%\n",
            "Make America great again! us us us us else attacks fight considered from stevens to iran and the plain art of the u bad\n",
            "Temperature is set at 150%\n",
            "Make America great again! us us else us does or own north connecticut four tweetend producer jumping donald stopping maker reading ironic kiss official\n",
            "Temperature is set at 200%\n",
            "Make America great again! us us else us debbie leaders isn't others cannot reps fire some where taxpayer controls endorsed republicans podesta march few\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XN7RTyVxm8",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Wiki words 250 normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGCotpiTpuZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_text_dataset(data, window_length, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "    dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_length, drop_remainder=True))\n",
        "    dataset = dataset.shuffle(math.ceil(len(data) / n_steps))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, -1:]), num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.map(\n",
        "        lambda xs, ys: (tf.strings.reduce_join(xs, axis=1, separator=' '), table.lookup(tf.squeeze(ys))),\n",
        "        num_parallel_calls=AUTOTUNE,\n",
        "    )\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJOVNWlGX8OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data = tf.constant(text_words)\n",
        "text_data_size = len(text_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_FH_M70V2rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_dataset = make_text_dataset(text_data, window_length, BATCH_SIZE)\n",
        "text_data_steps = math.ceil(text_data_size / BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQNil82yvKhZ",
        "colab_type": "code",
        "outputId": "53edb27c-c448-4b2d-8b8e-80e58c72bb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "text_dataset.element_spec"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(256,), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(256,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQibuRnoXqv-",
        "colab_type": "code",
        "outputId": "97dc6478-395a-414b-8539-4b8c91f71d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for xs, ys in text_dataset.take(1):\n",
        "    print(xs.shape, ys.shape)\n",
        "    print(xs[0])\n",
        "    print(ys[0])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256,) (256,)\n",
            "tf.Tensor(b\"yet her loss in a landslide that they don't know what to do tweetend just met with general petraeus was very impressed tweetend serious voter fraud in virginia new hampshire and california so why isn't the media reporting on this serious bias big problem tweetend it would have been much easier for me to win the so called popular vote than the electoral college\", shape=(), dtype=string)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_haQC3b6JCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hub_model(\n",
        "    model_url,\n",
        "    n_categories,\n",
        "    dropout,\n",
        "    l1,\n",
        "    l2,\n",
        "):\n",
        "    input_layer = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "    hub_layer = hub.KerasLayer(model_url)(input_layer)\n",
        "    batch_norm_layer = keras.layers.BatchNormalization()(hub_layer)\n",
        "    dropout_layer = keras.layers.Dropout(dropout)(batch_norm_layer)\n",
        "    output_layer = keras.layers.Dense(\n",
        "        n_categories,\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
        "        activation=keras.activations.softmax,\n",
        "    )(dropout_layer)\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJbmcumA0JVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    epochs,\n",
        "    lrs=None,\n",
        "    optimizers=None,\n",
        "    verbose=1,\n",
        "):\n",
        "    if optimizers is None:\n",
        "        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\n",
        "\n",
        "    model.layers[0].trainable = False\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[0],\n",
        "    )\n",
        "    model.fit(\n",
        "        text_dataset,\n",
        "        steps_per_epoch=text_data_steps,\n",
        "        epochs=epochs[0],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "            keras.callbacks.TerminateOnNaN(),\n",
        "        ],\n",
        "        verbose=verbose,\n",
        "    )\n",
        "\n",
        "    model.layers[0].trainable = True\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[1],\n",
        "    )\n",
        "    history = model.fit(\n",
        "        text_dataset,\n",
        "        steps_per_epoch=text_data_steps,\n",
        "        epochs=epochs[1],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=13, restore_best_weights=True),\n",
        "            keras.callbacks.TerminateOnNaN(),\n",
        "        ],\n",
        "        verbose=verbose,\n",
        "    )\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsgR8D0042y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/Wiki-words-250-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPvLcRnLJHSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK8w1e4S5dlm",
        "colab_type": "code",
        "outputId": "9dfc5c63-996e-47d1-bb46-d52a7cd943c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 10.6358\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 9.8457\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 9.0970\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.7979\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.5342\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.1450\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.6718\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.3257\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.1401\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 7.0388\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.9780\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9394\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9131\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8915\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.8758\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8571\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8451\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8298\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8179\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 43ms/step - loss: 6.8085\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7979\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.7873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UfYkRQPTGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_next_word(model, text, temperature=1):\n",
        "    prediction_input = tf.constant([text], dtype=tf.string)\n",
        "    prediction_probs = model.predict(prediction_input)\n",
        "    rescaled_logits = tf.math.log(prediction_probs) / temperature\n",
        "    word_index = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "    word = vocabulary[tf.squeeze(word_index)]\n",
        "    return word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94v8BDU4O20p",
        "colab_type": "code",
        "outputId": "54ed6290-d6af-4559-fe41-38e9e5356598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice\n",
            "Temperature is set at 50%\n",
            "Make America great again! celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice\n",
            "Temperature is set at 100%\n",
            "Make America great again! on celebapprentice celebapprentice clinton running rebels wall as celebapprentice play nbc realdonaldtrump ows establishment celebapprentice celebapprentice insane celebapprentice cruz realdonaldtrump\n",
            "Temperature is set at 150%\n",
            "Make America great again! they're informed he larry parade factor of realdbp enforcement jurciuoli19 worth boom other killed clips… you clinton insecure magazine trump2016\n",
            "Temperature is set at 200%\n",
            "Make America great again! allow sunday manage respect beliefheals wild slaughter tump2016 karlrove post bought explode fire senscottbrown 38 thunder trillion spending team are\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvUCLNSCyRUA",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Wiki words 500 normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qfeDPncyVi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/Wiki-words-500-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1dMlJh1yYK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0F3gLoVyY3S",
        "colab_type": "code",
        "outputId": "7596bc8a-8cc2-408e-b6bd-e6ebf4a7430d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 12.3574\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 10.7756\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 9.3649\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.8317\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.3506\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.7532\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 7.3402\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.1506\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.0592\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.0119\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9752\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9510\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 6.9281\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.9100\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8944\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8770\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8625\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8488\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8362\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8246\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8141\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.8031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTuQslA0yagR",
        "colab_type": "code",
        "outputId": "a3ca9f16-9dd5-477e-b650-21612b72efcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice\n",
            "Temperature is set at 50%\n",
            "Make America great again! realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice realdonaldtrump celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice realdonaldtrump celebapprentice celebapprentice\n",
            "Temperature is set at 100%\n",
            "Make America great again! is celebapprentice tune celebapprentice we like celebapprentice arsenioofficial ready 8 for realdonaldtrump her same thank one sam celebapprentice were tonight\n",
            "Temperature is set at 150%\n",
            "Make America great again! thanking lane border sells light settle combination trump thank williamgardanis facts the cuban busey podium website collect kind sales champion\n",
            "Temperature is set at 200%\n",
            "Make America great again! enter trump's feb country schlafly rampant ambassador to highlander6700 manager trumpnationalcharlotte credible issued pdf… largest extra we trumps assault latoyajackson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTRPjcYazdbz",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - nnlm 50 dims normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iA4r0qmzemZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50-with-normalization/1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHCnQZUVzgyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8lQ2GezgRG",
        "colab_type": "code",
        "outputId": "d286064f-28db-4d13-f919-55197a4a7149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 20s 50ms/step - loss: 9.1799\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 9.0147\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 20s 49ms/step - loss: 8.8397\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 8.7462\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.6625\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.5517\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.3955\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.1876\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.9366\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.6849\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.4735\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.3144\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.1922\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.0983\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.0302\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.9769\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9358\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9009\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8739\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.8524\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8357\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMXZqOjVzfgv",
        "colab_type": "code",
        "outputId": "0a3b567c-9222-427b-c661-0fed0ca98358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend the the is tweetend the on is tweetend tweetend the the a is i a the the of the\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend trump tweetend on and the making my on morning want to last the you is tweetend time a on\n",
            "Temperature is set at 100%\n",
            "Make America great again! business city and you be wnd special 90 be what again user offer tweetend by you no tweetend china will\n",
            "Temperature is set at 150%\n",
            "Make America great again! 46 terrorist ribbon incredible bobvanderplaats' except 02 tweetend don't expert ruined incentive ginhay supported dead minded the heavy barre espn\n",
            "Temperature is set at 200%\n",
            "Make America great again! far trumpcollection handed respect gala crimea underway service snurk enjoy shots gain spielberg wharton danscavino intelligence sink cleveland ruth introduce\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywD4AIQqmfNH",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - nnlm 128 dims normalized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYLzJcopYRMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHNXM-CsnFr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y83dDEwtnHgP",
        "colab_type": "code",
        "outputId": "37492ec5-e638-4461-cbc6-17dd4b528ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 9.7562\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 9.3501\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 8.9457\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.7671\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.6078\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.3794\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.0521\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.6769\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.3765\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.1844\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.0632\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.9831\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.9281\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.8880\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.8626\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8367\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.8192\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 6.8016\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7876\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7759\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 6.7614\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 6.7521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv1rYF8JnnTb",
        "colab_type": "code",
        "outputId": "6a5d0719-1026-46f1-b000-cdefd90121be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! tweetend i you the is tweetend you on the you and the the you to you will be the be\n",
            "Temperature is set at 50%\n",
            "Make America great again! tweetend is i foxandfriends foxandfriends a tweetend a but is you i a and is the and in the in\n",
            "Temperature is set at 100%\n",
            "Make America great again! m a america poll did entered democrat because live and tweetend of and great chaos put entrepreneurship ratings at what\n",
            "Temperature is set at 150%\n",
            "Make America great again! households then handsome produced didn't investments else allenwest defeat about player karlrove friend pac them erictrumpfdn neither straw after drug\n",
            "Temperature is set at 200%\n",
            "Make America great again! disappointed shortcakessheep of j program despise you wrote boxing bobby option had trump it very asp know did personally homeland\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-rYBaD4_PF",
        "colab_type": "text"
      },
      "source": [
        "### ***TF Hub Model - Google News Swivel 20 dims***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7V7MFI2nzBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbJ3j_f5B5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_hub_model(\n",
        "    model_url=url,\n",
        "    n_categories=vocabulary_size,\n",
        "    dropout=0.3,\n",
        "    l1=1e-4,\n",
        "    l2=1e-6,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM1vDDNB5Mlu",
        "colab_type": "code",
        "outputId": "7874effa-83e5-4288-ce32-aa676a15967e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model, history = train_model(\n",
        "    model=model,\n",
        "    epochs=[max(1, EPOCHS // 10), EPOCHS],\n",
        "    optimizers=[keras.optimizers.Adam(lr=LEARN_RATE * 0.3), keras.optimizers.Adam(lr=LEARN_RATE)],\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 411 steps\n",
            "Epoch 1/2\n",
            "411/411 [==============================] - 19s 47ms/step - loss: 8.9553\n",
            "Epoch 2/2\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.8828\n",
            "Train for 411 steps\n",
            "Epoch 1/20\n",
            "411/411 [==============================] - 20s 48ms/step - loss: 8.7975\n",
            "Epoch 2/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.7393\n",
            "Epoch 3/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.6869\n",
            "Epoch 4/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.6263\n",
            "Epoch 5/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 8.5490\n",
            "Epoch 6/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 8.4515\n",
            "Epoch 7/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 8.3295\n",
            "Epoch 8/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.1849\n",
            "Epoch 9/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 8.0223\n",
            "Epoch 10/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.8557\n",
            "Epoch 11/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.6931\n",
            "Epoch 12/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.5442\n",
            "Epoch 13/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.4123\n",
            "Epoch 14/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.3005\n",
            "Epoch 15/20\n",
            "411/411 [==============================] - 19s 46ms/step - loss: 7.2091\n",
            "Epoch 16/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.1319\n",
            "Epoch 17/20\n",
            "411/411 [==============================] - 19s 45ms/step - loss: 7.0691\n",
            "Epoch 18/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 7.0177\n",
            "Epoch 19/20\n",
            "411/411 [==============================] - 18s 45ms/step - loss: 6.9719\n",
            "Epoch 20/20\n",
            "411/411 [==============================] - 18s 44ms/step - loss: 6.9366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJi3bnjs5TSf",
        "colab_type": "code",
        "outputId": "443582b4-1299-44b7-eb8c-f9dba890fcbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "generate_samples(model, 'Make America great again!', 20, [0.2, 0.5, 1, 1.5, 2])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Temperature is set at 20%\n",
            "Make America great again! at of the tweetend tweetend the the a tweetend a the a tweetend the tweetend tweetend a tweetend the on\n",
            "Temperature is set at 50%\n",
            "Make America great again! the trump you of is can the great tweetend tweetend on at tweetend be and on lies m and tweetend\n",
            "Temperature is set at 100%\n",
            "Make America great again! tweetend drugs johnlegere up doctors 9 speech to lil rizz reason our straw after remembering right again world qaeda rolls\n",
            "Temperature is set at 150%\n",
            "Make America great again! lobbyists code punished area slow watch warming bunch interest court monstrosity a tee season concert apprenticenbc lied profit sneak news\n",
            "Temperature is set at 200%\n",
            "Make America great again! usc gravismarketing learn donaldjtrumpjr haul increases for countryside talking throwing hell www1 dumbest islam records whitney forces matches fayetteville irrelevant\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}